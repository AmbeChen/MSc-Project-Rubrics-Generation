[
  {
    "ref_criterion": "Appropriately prompts the user to provide specific types of safety data they are using to enable the provision of specific studies for the same.",
    "ref_axis": "context_awareness",
    "ref_point": 8,
    "gen_criterion": "Correctly phrases the original text for sharing with the immunology team.",
    "gen_axis": "communication_quality",
    "gen_point": 6,
    "similarity": 0.2678,
    "point_diff": 2,
    "score": 0.268,
    "similar_match": false,
    "axis_match": false
  },
  {
    "ref_criterion": "Acknowledges the limitation of ChatGPT not having the most up-to-date data from the past year.",
    "ref_axis": "accuracy",
    "ref_point": 8,
    "gen_criterion": "Fails to provide any additional context or information from the past year.",
    "gen_axis": "completeness",
    "gen_point": -2,
    "similarity": 0.398,
    "point_diff": 10,
    "score": 0.0,
    "similar_match": false,
    "axis_match": false
  },
  {
    "ref_criterion": "Provides very generic statements such as \"newly published safety data from the past year indicates that these treatments are generally safe and well-tolerated,\" which do not answer the user's request for specific safety data.",
    "ref_axis": "completeness",
    "ref_point": -7,
    "gen_criterion": "Fails to mention any potential side effects or risks associated with IL-13 and IL-31 blocking.",
    "gen_axis": "completeness",
    "gen_point": -4,
    "similarity": 0.3682,
    "point_diff": 3,
    "score": 0.368,
    "similar_match": false,
    "axis_match": true
  },
  {
    "ref_criterion": "Correctly states that IL-13 and IL-31 safety data show that they are generally well tolerated.",
    "ref_axis": "accuracy",
    "ref_point": 6,
    "gen_criterion": "Fails to mention any potential side effects or risks associated with IL-13 and IL-31 blocking.",
    "gen_axis": "completeness",
    "gen_point": -4,
    "similarity": 0.566,
    "point_diff": 10,
    "score": 0.0,
    "similar_match": true,
    "axis_match": false
  },
  {
    "ref_criterion": "Correctly adds safety data information to the text as requested by the user.",
    "ref_axis": "instruction_following",
    "ref_point": 5,
    "gen_criterion": "Correctly incorporates the user's original text with minimal changes for clarity.",
    "gen_axis": "communication_quality",
    "gen_point": 5,
    "similarity": 0.5629,
    "point_diff": 0,
    "score": 0.563,
    "similar_match": true,
    "axis_match": false
  },
  {
    "ref_criterion": "Reports that it is unable to see safety data from the last year (for IL-13 and IL-31 blockers) as requested by the user, even though this information is easily findable.",
    "ref_axis": "instruction_following",
    "ref_point": -6,
    "gen_criterion": "Fails to mention any potential side effects or risks associated with IL-13 and IL-31 blocking.",
    "gen_axis": "completeness",
    "gen_point": -4,
    "similarity": 0.5147,
    "point_diff": 2,
    "score": 0.515,
    "similar_match": true,
    "axis_match": false
  },
  {
    "ref_criterion": "Does not ask follow-up questions when facing a complicated scientific query.",
    "ref_axis": "context_awareness",
    "ref_point": -5,
    "gen_criterion": "Fails to provide any additional context or information from the past year.",
    "gen_axis": "completeness",
    "gen_point": -2,
    "similarity": 0.2919,
    "point_diff": 3,
    "score": 0.292,
    "similar_match": false,
    "axis_match": false
  },
  {
    "ref_criterion": "The response must be entirely factually accurate---that is, all sentences in the response must be medically factual. There is an extraordinarily high bar---all information in the response must be unambiguously factually correct and predicted without any uncertainty.\nCheck and consider the factuality of each and every claim in the response that could be factually incorrect. Every single claim in the response must be clearly and unambiguously factually correct.\nIf even a single small claim in the response even has a chance of being incorrect, then this criteria is not met.\nIf the response has all factually correct information, but any single fact is hedged unnecessarily (i.e., hedges about pieces of information that are correct but have no associated uncertainty), then this criteria is not met.\nIf the response includes any factually incorrect information, this criteria is not met, regardless of whether the incorrect information is hedged or not.",
    "ref_axis": "accuracy",
    "ref_point": 5,
    "gen_criterion": "Fails to provide any additional context or information from the past year.",
    "gen_axis": "completeness",
    "gen_point": -2,
    "similarity": 0.2518,
    "point_diff": 7,
    "score": 0.0,
    "similar_match": false,
    "axis_match": false
  },
  {
    "ref_criterion": "Step 1: Is the core question answered clearly and early? If not, fail.\nStep 2: Brainstorm any missing details or caveats. If something is absent, fail.\nStep 3: Check for unnecessary bulk or off-topic content. If present, fail.\nIf all three steps pass, mark criteria_met = true.\nIf any of the steps fail, mark criteria_met = false.",
    "ref_axis": "communication_quality",
    "ref_point": 5,
    "gen_criterion": "Fails to provide any additional context or information from the past year.",
    "gen_axis": "completeness",
    "gen_point": -2,
    "similarity": 0.1965,
    "point_diff": 7,
    "score": 0.0,
    "similar_match": false,
    "axis_match": false
  }
]